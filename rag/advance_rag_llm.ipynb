{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG w/ Re-Ranking | Groq + Ollama + LangChain + Cohere + PineCone + Llama3-70B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook demonstrates an advanced implementation of the Retrieval-Augmented Generation (RAG) technique, enhanced with document re-ranking, to generate precise summaries based on a given query. The process involves several key steps:\n",
    "\n",
    "1. **Importing Libraries**: Sets up the environment by importing necessary Python libraries for PDF processing, text splitting, embeddings, and API interactions.\n",
    "2. **Language Model Setup with Groq**: Initializes a language model using Groq's platform, leveraging the Llama3 model with 8 billion parameters for generating responses.\n",
    "3. **PDF Text Processing**: Reads and processes text from a PDF document, splitting it into manageable chunks for further processing.\n",
    "4. **Document Embedding with Ollama**: Utilizes the Ollama embeddings to convert text chunks into vector representations.\n",
    "5. **Pinecone Indexing**: Sets up a Pinecone vector database for storing and querying document embeddings.\n",
    "6. **Query Embedding and Retrieval**: Embeds a user query for similarity search in the Pinecone index, retrieving relevant document chunks.\n",
    "7. **Re-Ranking with Cohere**: Applies Cohere's re-ranking model to refine the search results, ensuring the most relevant documents are selected.\n",
    "8. **Summary Generation**: Uses the Groq language model to generate a comprehensive summary based on the context provided by the re-ranked documents.\n",
    "\n",
    "This notebook serves as a comprehensive guide for implementing a sophisticated RAG system with re-ranking, showcasing the integration of multiple AI and NLP technologies to enhance information retrieval and summarization tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting cohere\n",
      "  Using cached cohere-5.5.8-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-4.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from groq)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from groq)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting sniffio (from groq)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from groq) (4.12.2)\n",
      "Collecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
      "  Using cached boto3-1.34.140-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Using cached fastavro-1.9.4-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
      "  Using cached parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from cohere) (0.19.1)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
      "  Using cached types_requests-2.32.0.20240622-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.31-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\n",
      "  Downloading langchain_core-0.2.11-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.83-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from pinecone-client) (2024.6.2)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from pinecone-client) (2.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Collecting botocore<1.35.0,>=1.34.140 (from boto3<2.0.0,>=1.34.0->cohere)\n",
      "  Using cached botocore-1.34.140-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
      "  Using cached s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.6-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m762.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->groq)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1.9.0->groq)\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from tokenizers<1,>=0.15->cohere) (0.23.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.140->boto3<2.0.0,>=1.34.0->cohere) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.5.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.140->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
      "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
      "Using cached cohere-5.5.8-py3-none-any.whl (173 kB)\n",
      "Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_client-4.1.2-py3-none-any.whl (216 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.4/216.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached boto3-1.34.140-py3-none-any.whl (139 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached fastavro-1.9.4-cp311-cp311-macosx_10_9_universal2.whl (1.1 MB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Downloading pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading SQLAlchemy-2.0.31-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached types_requests-2.32.0.20240622-py3-none-any.whl (15 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached botocore-1.34.140-py3-none-any.whl (12.4 MB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.6-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: types-requests, tenacity, SQLAlchemy, sniffio, PyPDF2, pydantic-core, pinecone-plugin-interface, parameterized, orjson, jsonpointer, jmespath, httpx-sse, h11, fastavro, distro, annotated-types, pydantic, pinecone-client, jsonpatch, httpcore, botocore, anyio, s3transfer, langsmith, httpx, ollama, langchain-core, groq, boto3, langchain-text-splitters, cohere, langchain\n",
      "Successfully installed PyPDF2-3.0.1 SQLAlchemy-2.0.31 annotated-types-0.7.0 anyio-4.4.0 boto3-1.34.140 botocore-1.34.140 cohere-5.5.8 distro-1.9.0 fastavro-1.9.4 groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-core-0.2.11 langchain-text-splitters-0.2.2 langsmith-0.1.83 ollama-0.2.1 orjson-3.10.6 parameterized-0.9.0 pinecone-client-4.1.2 pinecone-plugin-interface-0.0.7 pydantic-2.8.2 pydantic-core-2.20.1 s3transfer-0.10.2 sniffio-1.3.1 tenacity-8.5.0 types-requests-2.32.0.20240622\n"
     ]
    }
   ],
   "source": [
    "!pip install groq ollama cohere langchain pinecone-client PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your Environment Variables to hit the varietry of different API's\n",
    "\n",
    "- GROQ_API_KEY\n",
    "- PINECONE_API_KEY\n",
    "- COHERE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Language Model with Groq\n",
    "\n",
    "Let's now set up the language model with Groq, Llama3 8 Billion Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_local = ChatOllama(model=\"mistral:instruct\")\n",
    "from os import getenv\n",
    "from groq import Groq\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY=getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "llm_groq = ChatGroq(\n",
    "            groq_api_key=GROQ_API_KEY,\n",
    "            model_name='llama3:8b' \n",
    "            # model_name='mixtral-8x7b-32768'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and Split PDF Text\n",
    "\n",
    "Reads text from a specified PDF file, concatenates it into a single string, and then splits the text into manageable chunks for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the PDF file\n",
    "pdf = PyPDF2.PdfReader(\"/Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/groq/data/Merged_Document.pdf\")\n",
    "pdf_text = \"\"\n",
    "for page in pdf.pages:\n",
    "    pdf_text += page.extract_text()\n",
    "\n",
    "# Split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed Documents with Ollama Embeddings\n",
    "\n",
    "Let's pull down a Ollama Embedding model.\n",
    "\n",
    "If you have ollama install, run this in your terminal:\n",
    "\n",
    "`ollama pull nomic-embed-text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "r1 = embeddings.embed_documents(\n",
    "    texts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pinecone Index Setup and Upsert\n",
    "\n",
    "Configures Pinecone for vector database operations, creates or connects to an index, and upserts document embeddings. Also defines a function to get query embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done upserting...\n"
     ]
    }
   ],
   "source": [
    "from os import getenv\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "PINECONE_API_KEY=getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index = pc.Index(\"ai-index\")\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    index.upsert([((str(i),r1[i],{\"text\":texts[i]}))])\n",
    "    \n",
    "print(\"done upserting...\")\n",
    "\n",
    "def get_query_embdedding(text):\n",
    "    embedding=embeddings.embed_query(text)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohere Setup and Query Embedding\n",
    "\n",
    "Initializes the Cohere client with an API key, generates an embedding for a query, and performs a vector search in the Pinecone index to find similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "COHERE_API_KEY=getenv(\"COHERE_API_KEY\")\n",
    "# init client\n",
    "co = cohere.Client(COHERE_API_KEY)\n",
    "\n",
    "query=\"what is 2 factor authentication?\"\n",
    "\n",
    "question_embedding=get_query_embdedding(query)\n",
    "\n",
    "query_result = index.query(vector=question_embedding, top_k=5, include_metadata=True)\n",
    "similar_texts = []\n",
    "# Extract metadata from query result\n",
    "docs = {x[\"metadata\"]['text']: i for i, x in enumerate(query_result[\"matches\"])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes the Cohere client with an API key, generates an embedding for a query, and performs a vector search in the Pinecone index to find similar documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Re-ranking with Cohere\n",
    "\n",
    "Uses Cohere's re-ranking model to refine the search results based on relevance to the query, then prepares a template for generating a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Two-step verification helps protect your account. When you log in, you'll be asked to provide a\\none-time code that you'll receive through email, text, or an authenticator app. If one of the methods\\nisn't working, try a different method. You'll also receive a backup code when you enable two-step\\nverification, which lets you access your account. If you don't have your backup code, contact the\\nFSA help center: https://studentaid.gov/help-center/contactIf you created an FSA ID with a SSN, it will take 1-3 days to be verified.\\nIf a parent/contributor created an FSA ID without an SSN and successfully answered the knowledge\\nbased identity questions, it can be used immediately. If unable to confirm identity, an email will be\\nsent with a case number and instructions to submit additional documents. Contributors can complete\", 'Find out how to stay eligible for federal student aid https://studentaid.gov/understand-aid/eligibility/staying-eligible.\\nRegaining Eligibility\\nIf you’ve been told you no longer qualify for federal student aid, ﬁnd out how to get your eligibility back https://studentaid.gov/understand-aid/eligibility/regain.\\nAuthenticator apps are downloaded to your mobile device and are used to generate secure six-digit codes you use to sign in to your accounts. This two-step veriﬁcation method oﬀers more security than other methods against phishing, hacking, and interception of text messages or email.\\nYou must set up at least one two-step veriﬁcation method (SMS text, email, or authenticator app). While SMS text and emails are options for receiving your authentication code (see below), we highly recommend using an authenticator app. (Using an authenticator app is not required to create a StudentAid.gov account.) \\nAuthenticator apps\\n•aren’t reliant on your cell or internet service,', 'Authenticator apps\\n•aren’t reliant on your cell or internet service,\\n•aren’t impacted by any email delivery delays or outages,\\n•provide increased security, and\\n•are generally faster than email or SMS text.\\nStep 1: Install an authenticator app\\nYou can use an authenticator app already on your mobile phone, or you can download a new one from your mobile app store. Some popular options are Google Authenticator, Microsoft Authenticator, Authy, LastPass, and Duo Mobile.\\nStep 2: Complete the app setup process\\nOnce you’ve installed an authenticator app, log in to your StudentAid.gov account. Select “Two-Step Veriﬁcation” in Settings, then select “Set Up an Authenticator App” and complete the process.', 'Once you’ve installed an authenticator app, log in to your StudentAid.gov account. Select “Two-Step Veriﬁcation” in Settings, then select “Set Up an Authenticator App” and complete the process.\\nWhile setting up, you’ll need to open your authenticator app and select the option to add an account (exact language will vary by app). You’ll be prompted to scan a QR code or enter a key in order to associate your authentication app with your StudentAid.gov account. To complete setup, you’ll enter the veriﬁcation code provided by your authentication app on StudentAid.gov.\\n\\xa0\\nStep 3: Log in!\\nOnce setup is complete, you can use your authenticator app to log in to StudentAid.gov.\\n\\xa0\\nAlternative two-step veriﬁcation methods\\nAlternatively, you can use the SMS text or email option to receive your authentication code. An email or mobile phone (for SMS text) must be veriﬁed in order to be used for two-step veriﬁcation.\\nA\\xa0StudentAid.gov\\xa0account is locked after three unsuccessful attempts to log in.', '4.Provide the month and date of your birth and select the “Continue” button. If you choose to use the authenticator app option, you won’t be asked for your date of birth.\\n5.After entering your secure code or answering some of your challenge questions, you’ll be prompted to create a new password.\\nI don’t remember my username or password\\nOn the Log In page, select “Forgot My Username” or “Forgot My\\xa0Password” to get into your account. You’ll need to access a one-time code through your veriﬁed email or mobile phone or through an authenticator app. You can use your challenge questions, but for security purposes there’s a 30-minute timeout before you can log in again.\\xa0Note:\\xa0You can use your veriﬁed email or mobile phone instead of your username to log in.\\nRemember:\\xa0If you have a veriﬁed email or mobile phone or authenticator app associated with your account, you can unlock your account, reset your password, or ﬁnd your username through that method or by using your challenge questions.']\n"
     ]
    }
   ],
   "source": [
    "# Rerank the documents\n",
    "rerank_docs = co.rerank(\n",
    "    model=\"rerank-english-v3.0\",\n",
    "    query=query, \n",
    "    documents=list(docs.keys()), \n",
    "    top_n=5, \n",
    "    return_documents=True\n",
    ")\n",
    "# print(\"rerank_docs...\",rerank_docs)\n",
    "\n",
    "# Extract reranked documents\n",
    "reranked_texts = [doc.document.text for doc in rerank_docs.results]\n",
    "print(reranked_texts)\n",
    "\n",
    "context=\" \".join(reranked_texts)\n",
    "\n",
    "Template = f\"Based on the following context : {context} generate precise summary related to question : {query} Do not remove necessary information related to context. Consider `\\n` as newline character.\"  \n",
    "# Filling the template with the actual context and question.\n",
    "filled_template = Template.format(context=context, question=query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses Cohere's re-ranking model to refine the search results based on relevance to the query, then prepares a template for generating a summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Summary with Groq\n",
    "\n",
    "Configures the Groq client, sends the filled template to the chat model for processing, and prints the generated summary based on the context and query provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a precise summary related to the question \"What is 2-factor authentication?\" based on the provided context:\n",
      "\n",
      "**Two-Factor Authentication (2FA)**\n",
      "\n",
      "Two-factor authentication is an additional security layer that helps protect your account. When you log in, you'll be asked to provide a one-time code that you'll receive through:\n",
      "\n",
      "* Email\n",
      "* Text (SMS)\n",
      "* Authenticator app (highly recommended)\n",
      "\n",
      "This 2FA method provides more security than traditional passwords against phishing, hacking, and interception of text messages or email.\n",
      "\n",
      "**Authenticator Apps**\n",
      "\n",
      "Authenticator apps, such as Google Authenticator, Microsoft Authenticator, Authy, LastPass, and Duo Mobile, offer:\n",
      "\n",
      "* Increased security\n",
      "* Faster authentication than email or SMS text\n",
      "* No reliance on cell or internet service\n",
      "* No impact from email delivery delays or outages\n",
      "\n",
      "To set up an authenticator app:\n",
      "\n",
      "1. Install the app on your mobile device.\n",
      "2. Log in to your StudentAid.gov account, select \"Two-Step Verification\" in Settings, and complete the setup process.\n",
      "3. Open the authenticator app, select the option to add an account, and scan a QR code or enter a key to associate the app with your account.\n",
      "\n",
      "**Alternative 2FA Methods**\n",
      "\n",
      "Alternatively, you can use SMS text or email to receive your authentication code. An email or mobile phone must be verified in order to be used for two-step verification.\n",
      "\n",
      "By using 2-factor authentication, you add an extra layer of security to your account and help prevent unauthorized access.\n"
     ]
    }
   ],
   "source": [
    "from os import getenv\n",
    "from groq import Groq\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY=getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY ,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": filled_template,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we successfully demonstrated the advanced implementation of the Retrieval-Augmented Generation (RAG) technique, complemented by document re-ranking, to generate precise summaries from a given query. Through the integration of cutting-edge technologies and platforms such as Groq, Ollama, Pinecone, and Cohere, we showcased a sophisticated system capable of enhancing information retrieval and summarization tasks.\n",
    "\n",
    "Key takeaways include:\n",
    "- The ability to process and split PDF text into manageable chunks for further analysis.\n",
    "- The use of Ollama embeddings to convert text chunks into vector representations, facilitating efficient document retrieval.\n",
    "- The application of Pinecone's vector database for storing and querying document embeddings, enabling fast and scalable searches.\n",
    "- The implementation of Cohere's re-ranking model to refine search results, ensuring the selection of the most relevant documents.\n",
    "- The generation of comprehensive summaries using the Groq language model, based on the context provided by re-ranked documents.\n",
    "\n",
    "This notebook not only serves as a practical guide to implementing a RAG system with re-ranking but also illustrates the power of combining multiple AI and NLP technologies to solve complex problems in information retrieval and summarization. We hope this demonstration inspires further exploration and development of advanced NLP applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
