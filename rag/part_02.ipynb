{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.31-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n",
      "  Downloading langchain_core-0.2.28-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.3.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.1.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.6-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Downloading openai-1.38.0-py3-none-any.whl (335 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading aiohttp-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (384 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading langchain_core-0.2.28-py3-none-any.whl (379 kB)\n",
      "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.96-py3-none-any.whl (140 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Using cached pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached SQLAlchemy-2.0.31-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading aiohappyeyeballs-2.3.4-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached orjson-3.10.6-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, tenacity, sniffio, PyYAML, python-dotenv, packaging, orjson, numpy, networkx, multidict, jsonpointer, idna, h11, frozenlist, distro, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, aiosignal, pydantic, httpx, aiohttp, openai, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.31 aiohappyeyeballs-2.3.4 aiohttp-3.10.0 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.4.0 attrs-24.1.0 certifi-2024.7.4 charset-normalizer-3.3.2 distro-1.9.0 frozenlist-1.4.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-core-0.2.28 langchain-text-splitters-0.2.2 langsmith-0.1.96 multidict-6.0.5 networkx-3.3 numpy-1.26.4 openai-1.38.0 orjson-3.10.6 packaging-24.1 pydantic-2.8.2 pydantic-core-2.20.1 python-dotenv-1.0.1 requests-2.32.3 sniffio-1.3.1 tenacity-8.5.0 tqdm-4.66.4 typing-extensions-4.12.2 urllib3-2.2.2 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain networkx openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GraphRetriever' from 'langchain.retrievers' (/Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages/langchain/retrievers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphRetriever\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GraphRetriever' from 'langchain.retrievers' (/Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/.venv/lib/python3.11/site-packages/langchain/retrievers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers import GraphRetriever\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "# API access to llama-cloud\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-scI6sh17nAaHZMbb2sIWHkWAyLkzusaJNzfq9Dz1XJjKQhwx\"\n",
    "\n",
    "# Using OpenAI API for embeddings/llms\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import  VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "EMBEDDING_MODEL  = \"text-embedding-3-small\"\n",
    "GENERATION_MODEL = \"gpt-4\"\n",
    "\n",
    "llm = OpenAI(model=GENERATION_MODEL)\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while parsing the file '/Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/rag/AIAYN.pdf': [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'api.cloud.llamaindex.ai'. (_ssl.c:1006)\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "pdf_file_name = '/Users/williamzebrowski/Library/Mobile Documents/com~apple~CloudDocs/transform_llm/rag/AIAYN.pdf'\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\").load_data(pdf_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 0\n"
     ]
    }
   ],
   "source": [
    "# Check loaded documents\n",
    "\n",
    "print(f\"Number of documents: {len(documents)}\")\n",
    "\n",
    "for doc in documents:\n",
    "    print(doc.doc_id)\n",
    "    print(doc.text[:500] + '...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the documents using MarkdownElementNodeParser\n",
    "\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(llm=llm, num_workers=8)\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nodes into objects\n",
    "\n",
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(f\"Number of nodes: {len(base_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects: 0\n"
     ]
    }
   ],
   "source": [
    "TABLE_REF_SUFFIX = '_table_ref'\n",
    "TABLE_ID_SUFFIX  = '_table'\n",
    "\n",
    "# Check parsed objects \n",
    "\n",
    "print(f\"Number of objects: {len(objects)}\")\n",
    "\n",
    "for node in objects: \n",
    "    print(f\"id:{node.node_id}\")\n",
    "    print(f\"hash:{node.hash}\")\n",
    "    print(f\"parent:{node.parent_node}\")\n",
    "    print(f\"prev:{node.prev_node}\")\n",
    "    print(f\"next:{node.next_node}\")\n",
    "\n",
    "    # Object is a Table\n",
    "    if node.node_id[-1 * len(TABLE_REF_SUFFIX):] == TABLE_REF_SUFFIX:\n",
    "\n",
    "        if node.next_node is not None:\n",
    "            next_node = node.next_node\n",
    "        \n",
    "            print(f\"next_node metadata:{next_node.metadata}\")\n",
    "            print(f\"next_next_node:{next_next_nod_id}\")\n",
    "\n",
    "            obj_metadata = json.loads(str(next_node.json()))\n",
    "\n",
    "            print(str(obj_metadata))\n",
    "\n",
    "            print(f\"def:{obj_metadata['metadata']['table_df']}\")\n",
    "            print(f\"summary:{obj_metadata['metadata']['table_summary']}\")\n",
    "\n",
    "\n",
    "    print(f\"next:{node.next_node}\")\n",
    "    print(f\"type:{node.get_type()}\")\n",
    "    print(f\"class:{node.class_name()}\")\n",
    "    print(f\"content:{node.get_content()[:200]}\")\n",
    "    print(f\"metadata:{node.metadata}\")\n",
    "    print(f\"extra:{node.extra_info}\")\n",
    "    \n",
    "    node_json = json.loads(node.json())\n",
    "\n",
    "    print(f\"start_idx:{node_json.get('start_char_idx')}\")\n",
    "    print(f\"end_idx:{node_json['end_char_idx']}\")\n",
    "\n",
    "    if 'table_summary' in node_json: \n",
    "        print(f\"summary:{node_json['table_summary']}\")\n",
    "\n",
    "    print(\"=====================================\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llx-QsYcVLF2HyDxEj12cIRMIRDExu1wsyhgCbwyyom1Kk3dYBOg\n",
      "Error while parsing the file '<bytes/buffer>': [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'api.cloud.llamaindex.ai'. (_ssl.c:1006)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# bring in our LLAMA_CLOUD_API_KEY\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "LLAMA_CLOUD_API_KEY = os.environ['LLAMA_CLOUD_API_KEY']\n",
    "\n",
    "print(LLAMA_CLOUD_API_KEY)\n",
    "\n",
    "# bring in deps\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# set up parser\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    ")\n",
    "\n",
    "# use SimpleDirectoryReader to parse our file\n",
    "file_extractor = {\".pdf\": parser}\n",
    "documents = SimpleDirectoryReader(input_files=['insurance.pdf'], file_extractor=file_extractor).load_data()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
