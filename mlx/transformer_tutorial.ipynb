{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import mlx.utils as utils\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0, 'banana': 1, 'cherry': 2, 'date': 3, 'elderberry': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['apple', 'banana', 'cherry', 'date', 'elderberry']\n",
    "\n",
    "# Create a dictionary mapping words to indices\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding layer: Linear(input_dims=5, output_dims=4, bias=False)\n",
      "shape: (5, 4)\n",
      "embedding weights:\n",
      "\n",
      " array([[-0.750144, -0.715065, 0.163696, -0.00504255],\n",
      "       [-0.35809, 0.0659351, 0.206761, -0.0115913],\n",
      "       [0.306434, -0.388729, -0.304187, 0.106564],\n",
      "       [-0.341709, 0.92508, -0.250953, 0.40707],\n",
      "       [0.236226, -0.0690609, -0.225982, -0.485293]], dtype=float32) \n",
      "\n",
      "embedding weights shape: (5, 4)\n",
      "embedding weights dtype: mlx.core.float32\n",
      "embedding weights dimension: 2\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding dimension\n",
    "embedding_dim = 4\n",
    "\n",
    "embedding_layer = nn.Linear(input_dims=len(vocab), output_dims=embedding_dim, bias=False)\n",
    "\n",
    "print(f\"embedding layer: {embedding_layer}\")\n",
    "\n",
    "# Use the `uniform` function to create embedding weights\n",
    "low = -1.0   # Lower bound of the uniform distribution\n",
    "high = 1.0   # Upper bound of the uniform distribution\n",
    "shape = (len(vocab), embedding_dim)  # Shape of the output array\n",
    "\n",
    "print(f\"shape: {shape}\")\n",
    "\n",
    "# Generate the embedding weights using the `uniform` function\n",
    "embedding_weights = mx.random.uniform(low=low, high=high, shape=shape, dtype=mx.float32)\n",
    "\n",
    "print(f\"embedding weights:\\n\\n {embedding_weights} \\n\")\n",
    "print(f\"embedding weights shape: {embedding_weights.shape}\")\n",
    "print(f\"embedding weights dtype: {embedding_weights.dtype}\")\n",
    "print(f\"embedding weights dimension: {embedding_weights.ndim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.282818, 0.0747007, 0.689883, 0.829985],\n",
       "       [-0.101662, -0.478935, 0.522005, 0.82613],\n",
       "       [0.817008, 0.0659022, -0.226369, -0.439722],\n",
       "       [-0.834577, 0.701258, 0.327776, 0.577704],\n",
       "       [0.375136, -0.333818, 0.204179, 0.0162272]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.sin(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
